{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from os.path import basename\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.utils.data\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data with melspectrogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_location, width=200, height=140):\n",
    "    \n",
    "    #Get number of data files\n",
    "    num_samples = 0\n",
    "    for file_ in glob.glob(data_location + '/*.wav'):\n",
    "        num_samples+=1\n",
    "        \n",
    "    features = np.zeros((num_samples, 1, height, width), np.float32)\n",
    "    labels = np.zeros((num_samples), np.int64)\n",
    "    \n",
    "    # For shuffling\n",
    "    p = np.random.permutation(num_samples)\n",
    "    \n",
    "    file_num = 0\n",
    "    for file_ in glob.glob(data_location + '/*.wav'):\n",
    "        \n",
    "        # Record emotion type and intensity\n",
    "#         labels[p[file_num], int(basename(file_)[:-4].split('-')[2])-1] = 1.0\n",
    "#         labels[p[file_num], int(basename(file_)[:-4].split('-')[3])+7] = 1.0\n",
    "        emotionVar = int(basename(file_)[:-4].split('-')[2])\n",
    "        intensityVar = int(basename(file_)[:-4].split('-')[3])\n",
    "        labels[p[file_num]] = ((emotionVar-1)*2 + intensityVar - 1)\n",
    "        # Read file and extract features\n",
    "        X, sample_rate = librosa.load(file_, res_type='kaiser_fast')\n",
    "        file_feature = librosa.feature.melspectrogram(X, sample_rate)\n",
    "        file_feature = cv2.resize(librosa.power_to_db(file_feature, ref=np.max), (width, height))\n",
    "        features[p[file_num]] = file_feature.reshape((1, height, width))\n",
    "        \n",
    "        file_num+=1\n",
    "        \n",
    "    return {'features' : features, 'labels' : labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data('./Data', width = 300, height = 210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "features = data['features']\n",
    "labels = data['labels']\n",
    "X_train = features[:int((1-val_split)*features.shape[0])]\n",
    "y_train = labels[:int((1-val_split)*features.shape[0])]\n",
    "X_val = features[int((1-val_split)*features.shape[0]):]\n",
    "y_val = labels[int((1-val_split)*features.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 63000 into shape (140,200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-98ee9bcf7900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 63000 into shape (140,200)"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape((140, 200)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch!! Let's make a model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "width = 300\n",
    "height = 210\n",
    "num_epochs = 30\n",
    "batch_size = 6\n",
    "learning_rate = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_dataset = data_utils.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = data_utils.TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_acc():\n",
    "    crnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for in_features, labels in val_loader:\n",
    "        in_features = Variable(in_features).cuda()\n",
    "        labels = labels.cuda()\n",
    "    #     ids_type = torch.LongTensor([0,1,2,3,4,5,6]).cuda()\n",
    "    #     ids_intensity = torch.LongTensor([7,8]).cuda()\n",
    "        outputs = crnn(in_features)\n",
    "    #     outputs_type = nn.functional.softmax(outputs.data.index_select(1,ids_type))\n",
    "    #     outputs_intensity = nn.functional.softmax(outputs.data.index_select(1,ids_intensity))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    #     _, predicted_type = torch.max(outputs_type, 1)\n",
    "    #     _, predicted_intensity = torch.max(outputs_intensity, 1)\n",
    "    #     labels_type = labels.index_select(1,ids_type)\n",
    "    #     labels_intensity = labels.index_select(1,ids_intensity)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Validation Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN (\n",
       "  (layer1): Sequential (\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU ()\n",
       "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (rnn): LSTM(13, 256, bidirectional=True)\n",
       "  (fc1): Sequential (\n",
       "    (0): Linear (59904 -> 500)\n",
       "    (1): Dropout (p = 0.3)\n",
       "  )\n",
       "  (fc2): Linear (500 -> 16)\n",
       ")"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.rnn = nn.LSTM(height//16, 256, 1, bidirectional=True)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear((width//16)*(height//16)*256, 500),\n",
    "            nn.Dropout(0.3))\n",
    "#         self.fc1 = nn.Linear(256, 500)\n",
    "        self.fc2 = nn.Linear(500, 16)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = out.sum(1)\n",
    "#         out = out.view(out.size(2), out.size(0), out.size(1))\n",
    "#         out, (hn, cn) = self.rnn(out)\n",
    "#         out = out[-1]\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "crnn = CRNN()\n",
    "crnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(crnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Iter [192/192] Loss: 2.5534\n",
      "Validation Accuracy: 19 %\n",
      "Epoch [2/30], Iter [192/192] Loss: 1.7051\n",
      "Validation Accuracy: 25 %\n",
      "Epoch [3/30], Iter [192/192] Loss: 1.9400\n",
      "Validation Accuracy: 38 %\n",
      "Epoch [4/30], Iter [192/192] Loss: 1.5985\n",
      "Validation Accuracy: 42 %\n",
      "Epoch [5/30], Iter [192/192] Loss: 0.9775\n",
      "Validation Accuracy: 50 %\n",
      "Epoch [6/30], Iter [192/192] Loss: 0.5099\n",
      "Validation Accuracy: 48 %\n",
      "Epoch [7/30], Iter [192/192] Loss: 0.2248\n",
      "Validation Accuracy: 52 %\n",
      "Epoch [8/30], Iter [192/192] Loss: 0.9128\n",
      "Validation Accuracy: 52 %\n",
      "Epoch [9/30], Iter [192/192] Loss: 0.0954\n",
      "Validation Accuracy: 57 %\n",
      "Epoch [10/30], Iter [192/192] Loss: 0.0822\n",
      "Validation Accuracy: 58 %\n",
      "Epoch [11/30], Iter [192/192] Loss: 0.0444\n",
      "Validation Accuracy: 60 %\n",
      "Epoch [12/30], Iter [192/192] Loss: 0.0395\n",
      "Validation Accuracy: 56 %\n",
      "Epoch [13/30], Iter [192/192] Loss: 0.0328\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [14/30], Iter [192/192] Loss: 0.0294\n",
      "Validation Accuracy: 57 %\n",
      "Epoch [15/30], Iter [192/192] Loss: 0.0164\n",
      "Validation Accuracy: 57 %\n",
      "Epoch [16/30], Iter [192/192] Loss: 0.0384\n",
      "Validation Accuracy: 57 %\n",
      "Epoch [17/30], Iter [192/192] Loss: 0.0033\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [18/30], Iter [192/192] Loss: 0.0006\n",
      "Validation Accuracy: 63 %\n",
      "Epoch [19/30], Iter [192/192] Loss: 0.1272\n",
      "Validation Accuracy: 61 %\n",
      "Epoch [20/30], Iter [192/192] Loss: 0.0013\n",
      "Validation Accuracy: 60 %\n",
      "Epoch [21/30], Iter [192/192] Loss: 0.0054\n",
      "Validation Accuracy: 64 %\n",
      "Epoch [22/30], Iter [192/192] Loss: 0.0324\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [23/30], Iter [192/192] Loss: 0.0002\n",
      "Validation Accuracy: 62 %\n",
      "Epoch [24/30], Iter [192/192] Loss: 0.0194\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [25/30], Iter [192/192] Loss: 0.0038\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [26/30], Iter [192/192] Loss: 0.0075\n",
      "Validation Accuracy: 54 %\n",
      "Epoch [27/30], Iter [192/192] Loss: 0.1225\n",
      "Validation Accuracy: 59 %\n",
      "Epoch [28/30], Iter [192/192] Loss: 0.0773\n",
      "Validation Accuracy: 62 %\n",
      "Epoch [29/30], Iter [192/192] Loss: 0.7396\n",
      "Validation Accuracy: 56 %\n",
      "Epoch [30/30], Iter [192/192] Loss: 0.0019\n",
      "Validation Accuracy: 57 %\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (in_features, labels) in enumerate(train_loader):\n",
    "        crnn.train()\n",
    "        in_features = Variable(in_features).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = crnn(in_features)\n",
    "        writer.add_graph(crnn, outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "%(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "    get_val_acc()\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "crnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for in_features, labels in val_loader:\n",
    "    in_features = Variable(in_features).cuda()\n",
    "    labels = labels.cuda()\n",
    "#     ids_type = torch.LongTensor([0,1,2,3,4,5,6]).cuda()\n",
    "#     ids_intensity = torch.LongTensor([7,8]).cuda()\n",
    "    outputs = crnn(in_features)\n",
    "#     outputs_type = nn.functional.softmax(outputs.data.index_select(1,ids_type))\n",
    "#     outputs_intensity = nn.functional.softmax(outputs.data.index_select(1,ids_intensity))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "#     _, predicted_type = torch.max(outputs_type, 1)\n",
    "#     _, predicted_intensity = torch.max(outputs_intensity, 1)\n",
    "#     labels_type = labels.index_select(1,ids_type)\n",
    "#     labels_intensity = labels.index_select(1,ids_intensity)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
